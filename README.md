# Stochastic Gradient Ascent (SGA) – Logistic Regression Implementation

This repository contains a Python implementation of logistic regression using **Stochastic Gradient Ascent (SGA)**. The model is trained and evaluated on a binary classification dataset using `NumPy`, with a focus on understanding gradient-based optimization.

## 📁 Project Structure

* `SGA.ipynb`: Jupyter Notebook containing the full implementation of logistic regression using stochastic gradient ascent, with detailed explanations, code, and plots.

## 📌 Features

* Manual implementation of logistic regression (no scikit-learn)
* Uses stochastic gradient ascent to optimize weights
* Visualizes data and decision boundaries
* Includes evaluation metrics like accuracy

## 🧠 Key Concepts

* Logistic Regression
* Sigmoid Function
* Gradient Ascent
* Binary Classification
* Data Normalization

## 🛠️ Dependencies

* Python 3.x
* NumPy
* Matplotlib
* Jupyter Notebook

You can install the dependencies using:

```bash
pip install numpy matplotlib notebook
```

## 🚀 Getting Started

1. Clone the repository:

   ```bash
   git clone https://github.com/your-username/SGA-Logistic-Regression.git
   cd SGA-Logistic-Regression
   ```

2. Launch the notebook:

   ```bash
   jupyter notebook SGA.ipynb
   ```

3. Follow along with the cells to understand each step in the SGA training process.

## 📊 Example Output

The notebook includes visualizations of:

* Data distribution
* Sigmoid function behavior
* Decision boundary evolution over epochs

## 🧪 Results

The final model achieves good accuracy on a simple binary dataset, demonstrating the effectiveness of stochastic gradient ascent in optimizing logistic regression.
